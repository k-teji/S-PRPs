{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##' import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import optuna\n",
    "import glob\n",
    "import gc\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import data \n",
    "all_data = pd.read_csv('data/hPRB1-conc-data_1-1034_serum-and-saliva.csv')\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract features for the analysis\n",
    "feature_data = all_data.loc[:, ['Sample_ID', 'Saliva_hPRB1-normalised', 'Serum_hPRB1-normalised']]\n",
    "feature_data = feature_data.set_index('Sample_ID')\n",
    "feature_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the list of the disease to be predicted\n",
    "tbp_dfp_list = pd.read_csv('data/Disease_analysing-list.csv',encoding='shift-jis')\n",
    "tbp_dfp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function for optuna parameter tuning\n",
    "def objective(trial, used_input_data_train, predict_target_data, cv_fold_N):\n",
    "    max_depth = trial.suggest_int('max_depth',3,12)\n",
    "    num_leaves = trial.suggest_int('num_leaves',2,256)\n",
    "    subsample = trial.suggest_uniform('subsample',0.1,1.0)\n",
    "    subsample_freq = trial.suggest_int('subsample_freq',1,7)\n",
    "    colsample_bytree = trial.suggest_uniform('colsample_bytree',0.1,1.0)\n",
    "    min_child_samples = trial.suggest_int('min_child_samples',5,100)\n",
    "    \n",
    "    lgb_clf = lgb.LGBMClassifier(objective='binary',\n",
    "                                random_state=29,\n",
    "                                max_depth=max_depth,\n",
    "                                num_leaves=num_leaves,\n",
    "                                subsample=subsample,\n",
    "                                subsample_freq=subsample_freq,\n",
    "                                colsample_bytree=colsample_bytree,\n",
    "                                min_child_samples=min_child_samples)\n",
    "    \n",
    "    bagging_models = []\n",
    "    auc_results = []\n",
    "    \n",
    "    ## make models\n",
    "    cv_folds = StratifiedKFold(n_splits=cv_fold_N,\n",
    "                                shuffle=True,\n",
    "                                random_state=29)\n",
    "\n",
    "    i = 0\n",
    "    for train_index, test_index in cv_folds.split(used_input_data_train, predict_target_data):\n",
    "        explain_train, explain_test = used_input_data_train.iloc[train_index], used_input_data_train.iloc[test_index]\n",
    "        target_train, target_test = predict_target_data.iloc[train_index], predict_target_data.iloc[test_index]\n",
    "            \n",
    "        for j in range(100):\n",
    "            # Under sampling to set 1 on 1 in target label\n",
    "            sampler = RandomUnderSampler(random_state=j,\n",
    "                                        replacement=True)\n",
    "            x_resampled, y_resampled = sampler.fit_resample(explain_train, \n",
    "                                                            target_train)\n",
    "            \n",
    "            # make models\n",
    "            model_bagging = lgb_clf.fit(X = x_resampled,\n",
    "                                        y = y_resampled)\n",
    "            bagging_models.append(model_bagging)\n",
    "            \n",
    "            # calculate model predictions\n",
    "            if j == 0:\n",
    "                y_preds = pd.DataFrame({j: model_bagging.predict_proba(explain_test)[:,1]})\n",
    "            else:\n",
    "                y_preds = pd.concat([y_preds, pd.DataFrame({j: model_bagging.predict_proba(explain_test)[:,1]})], axis = 1)\n",
    "            \n",
    "        ## calculate y mean preds\n",
    "        y_preds_mean = y_preds.mean(axis=1)\n",
    "        y_auc = roc_auc_score(target_test, y_preds_mean)\n",
    "        auc_results.append(y_auc)\n",
    "\n",
    "        # increment i\n",
    "        i = i + 1\n",
    "    \n",
    "    mean_auc = pd.DataFrame(auc_results).mean()\n",
    "    \n",
    "    return mean_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set features list and error list\n",
    "feature_list = ['Saliva_hPRB1-normalised', 'Serum_hPRB1-normalised']\n",
    "err_list = []\n",
    "\n",
    "# Loop of the disease to be predicted\n",
    "for tbp_t in range(len(tbp_dfp_list)):\n",
    "    cur_dis_type = tbp_dfp_list.disease_class[tbp_t]\n",
    "    cur_dis_name = tbp_dfp_list.disease_name[tbp_t]\n",
    "    \n",
    "    print(tbp_t, ':', cur_dis_type, '__', cur_dis_name, ' --- ', datetime.datetime.today())\n",
    "    \n",
    "    cur_folder_data_fp = ''.join(['Disease_binary-data/',\n",
    "                                tbp_dfp_list.label[tbp_t]])\n",
    "    \n",
    "    cur_folder_data_fp = cur_folder_data_fp.replace('Single', 'single')\n",
    "    \n",
    "    cur_tbp_data = pd.read_csv(cur_folder_data_fp, \n",
    "                                index_col='Sample_ID',encoding='Shift-JIS')\n",
    "    \n",
    "    cur_disease = cur_tbp_data.columns[0]\n",
    "    \n",
    "    ## data merge\n",
    "    merge_data = pd.concat([cur_tbp_data, feature_data], axis=1)\n",
    "    \n",
    "    #for fea in [feature_list[0]]:\n",
    "    for fea in feature_list:\n",
    "        print(fea, '---', datetime.datetime.today())\n",
    "\n",
    "        analyse_data = merge_data.loc[:, [cur_disease, fea]].dropna(how='any',axis=0)\n",
    "        \n",
    "        used_input_data = analyse_data.loc[:,[fea]]\n",
    "        predict_target_data = analyse_data.loc[:,cur_disease]\n",
    "        \n",
    "        try:\n",
    "            ## tuning parameters by optuna\n",
    "            study = optuna.create_study(sampler=optuna.samplers.RandomSampler(seed=29),\n",
    "                                direction='maximize')\n",
    "            optuna.logging.disable_default_handler()\n",
    "            print('tuning-start')\n",
    "            study.optimize(lambda trial: objective(trial = trial,\n",
    "                            used_input_data_train=used_input_data,\n",
    "                            predict_target_data=predict_target_data,\n",
    "                            cv_fold_N=5),\n",
    "                            n_trials=50)\n",
    "            print('tuning-done')\n",
    "            \n",
    "            ## save best parameters\n",
    "            best_params_dict = study.best_params\n",
    "            \n",
    "            ## make models\n",
    "            cv_folds = StratifiedKFold(n_splits=5,\n",
    "                                        shuffle=True,\n",
    "                                        random_state=29)\n",
    "\n",
    "            result_auc = []\n",
    "            model_res = []\n",
    "\n",
    "            i = 0\n",
    "            for train_index, test_index in cv_folds.split(used_input_data, predict_target_data):\n",
    "                explain_train, explain_test = used_input_data.iloc[train_index], used_input_data.iloc[test_index]\n",
    "                target_train, target_test = predict_target_data.iloc[train_index], predict_target_data.iloc[test_index]\n",
    "                \n",
    "                ## evaluate test data\n",
    "                lgb_clf = lgb.LGBMClassifier(objective='binary',\n",
    "                                            random_state=29,\n",
    "                                            **study.best_params)\n",
    "                \n",
    "                bagging_models = []\n",
    "                \n",
    "                for j in range(100):\n",
    "                    # Under sampling to set 1 on 1 in target label\n",
    "                    sampler = RandomUnderSampler(random_state=j,\n",
    "                                                replacement=True)\n",
    "                    x_resampled, y_resampled = sampler.fit_resample(explain_train, \n",
    "                                                                    target_train)\n",
    "                    \n",
    "                    # make models\n",
    "                    model_bagging = lgb_clf.fit(X = x_resampled,\n",
    "                                                y = y_resampled)\n",
    "                    bagging_models.append(model_bagging)\n",
    "                    \n",
    "                    # calculate model predictions\n",
    "                    if j == 0:\n",
    "                        y_preds_test = pd.DataFrame({j: model_bagging.predict_proba(explain_test)[:,1]})\n",
    "                    else:\n",
    "                        y_preds_test = pd.concat([y_preds_test, pd.DataFrame({j: model_bagging.predict_proba(explain_test)[:,1]})], axis = 1)\n",
    "                    \n",
    "                ## calculate y mean preds for AUC analysis in test data\n",
    "                y_preds_test_mean = y_preds_test.mean(axis=1)\n",
    "                result_auc.append(roc_auc_score(target_test, y_preds_test_mean))\n",
    "                \n",
    "                ## save model \n",
    "                model_res.append(bagging_models)\n",
    "                \n",
    "                # increment i\n",
    "                i = i + 1\n",
    "            \n",
    "            # AUC result summary\n",
    "            result_auc_df = pd.DataFrame(result_auc).transpose()\n",
    "            result_auc_df.columns = ['CV_0', 'CV_1', 'CV_2', 'CV_3', 'CV_4']\n",
    "            result_auc_df = result_auc_df.assign(mean=lambda df: df.mean(axis=1),\n",
    "                                                std=lambda df: df.std(axis=1),feature = fea,\n",
    "                                                Analysis_type = cur_dis_type, disease_name = cur_dis_name,\n",
    "                                                Negative_SampleN = sum(analyse_data.iloc[:,0] == 0),\n",
    "                                                Positive_SampleN = sum(analyse_data.iloc[:,0] == 1))\n",
    "            result_auc_df = result_auc_df.reindex(columns = ['Analysis_type', 'disease_name', 'feature',\n",
    "                                                            'CV_0', 'CV_1', 'CV_2', 'CV_3', 'CV_4', 'mean', 'std',\n",
    "                                                            'Negative_SampleN', 'Positive_SampleN'])\n",
    "            \n",
    "            if fea == feature_list[0] and tbp_t == 0:\n",
    "                cum_auc = result_auc_df\n",
    "            else:\n",
    "                cum_auc = pd.concat([cum_auc, result_auc_df],axis=0)\n",
    "            \n",
    "            pd.to_pickle(model_res,\n",
    "                        ''.join(['results/', \n",
    "                                cur_dis_type, '--', cur_dis_name, '__by--', fea, '__models.pkl']))\n",
    "\n",
    "            cum_auc.to_csv('AUCs-results__all-predictions.csv',encoding='Shift-JIS',\n",
    "                            index=False)\n",
    "\n",
    "        except:\n",
    "            err_save_label = ''.join(['tbp__', cur_dis_type, '---', cur_dis_name, '__features__', fea])\n",
    "            err_list.append(err_save_label)\n",
    "\n",
    "        \n",
    "        ## delete study object\n",
    "        if 'study' in locals() or 'study' in globals():\n",
    "            del study\n",
    "        while 'study' in locals() or 'study' in globals():\n",
    "            time.sleep(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8cfd2a74008d7bd04b54778fc387d84beadb13d342fc612be7d330217f576bdf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
